# -*- coding: utf-8 -*-
"""Improved Backend

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZQsrMGp3Y48Blp9BSdchzbAMPgE-CWx7
"""

import time
import numpy as np
import torch
import torch.nn as nn
import scipy.signal
import joblib
import brainaccess
from brainaccess.utils import acquisition

TARGET_CHANNELS = ['AF3', 'AF4', 'O1', 'O2']
BANDS = {'Theta': (4, 8), 'Alpha': (8, 13), 'Beta': (13, 30), 'Gamma': (30, 45)}
TARGET_FS = 250

class EmotionNet(nn.Module):
    def __init__(self, input_size, num_classes):
        super(EmotionNet, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_size, 64),
            nn.BatchNorm1d(64),
            nn.LeakyReLU(0.1),
            nn.Dropout(0.5),
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.LeakyReLU(0.1),
            nn.Dropout(0.3),
            nn.Linear(32, num_classes)
        )
    def forward(self, x):
        return self.net(x)

class EnhancedPredictor:
    def __init__(self):
        self.device = torch.device('cpu')
        try:
            self.scaler = joblib.load('robust_scaler.pkl')
            # 24 features based on the new training script
            self.model = EmotionNet(input_size=24, num_classes=4)
            self.model.load_state_dict(torch.load('enhanced_model.pth', map_location=self.device))
            self.model.eval()
        except:
            print("Run train_enhanced.py first!")

    def extract_features(self, data):
        """Matches the training script exactly"""
        eps = 1e-10
        freqs, psd = scipy.signal.welch(data, TARGET_FS, nperseg=len(data), axis=0)

        powers = {ch: [] for ch in TARGET_CHANNELS}

        # 1. Log Powers
        for ch_idx, ch_name in enumerate(TARGET_CHANNELS):
            for band, (low, high) in BANDS.items():
                idx = np.logical_and(freqs >= low, freqs <= high)
                val = np.sum(psd[idx, ch_idx])
                powers[ch_name].append(np.log(val + eps))

        feature_vector = []
        # Raw features
        for ch in TARGET_CHANNELS:
            feature_vector.extend(powers[ch])

        # Asymmetry features
        for i in range(len(BANDS)):
            feature_vector.append(powers['AF3'][i] - powers['AF4'][i])
            feature_vector.append(powers['O1'][i] - powers['O2'][i])

        return np.array(feature_vector).reshape(1, -1)

    def predict(self, window):
        feats = self.extract_features(window)
        feats_scaled = self.scaler.transform(feats)

        with torch.no_grad():
            out = self.model(torch.tensor(feats_scaled).float())
            probs = torch.softmax(out, dim=1).numpy()[0]

        classes = ['Calm', 'Relaxed', 'Angry', 'Happy']
        best_idx = np.argmax(probs)
        return classes[best_idx], probs

def run_live():
    predictor = EnhancedPredictor()
    acquisition.connect()

    with acquisition.Streaming() as stream:
        all_chans = stream.get_channel_names()
        ids = [all_chans.index(ch) for ch in TARGET_CHANNELS]
        buffer = np.zeros((0, 4))

        print("\n=== CALIBRATION PHASE (5 Seconds) ===")
        print("Please sit still and relax...")
        time.sleep(1)

        # Calibration logic could go here (calculating baseline mean)
        # For now, we rely on RobustScaler which centers data well.

        print("\n=== LIVE CLASSIFICATION STARTED ===")
        while True:
            chunk = stream.get_data()
            if chunk is None or len(chunk) == 0: continue

            # Transpose if needed
            if chunk.shape[0] == len(all_chans): chunk = chunk.T

            # Select channels
            chunk = chunk[:, ids]

            # --- CRITICAL FIX: UNIT CONVERSION ---
            # If values are tiny (Volts), convert to Microvolts
            if np.mean(np.abs(chunk)) < 0.001:
                chunk = chunk * 1e6

            buffer = np.vstack([buffer, chunk])

            # Keep last 1 second (250 samples)
            buffer = buffer[-250:]

            if len(buffer) == 250:
                label, probs = predictor.predict(buffer)

                # Visual Bar
                p_str = " | ".join([f"{p:.2f}" for p in probs])
                color = "\033[92m" if label in ['Happy', 'Relaxed'] else "\033[91m"
                print(f"\r{color}Pred: {label}\033[0m [ {p_str} ]", end="")

            time.sleep(0.05)

if __name__ == "__main__":
    run_live()